{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tabelog_NegaPojiAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yk-mt12/project-exercise/blob/master/tabelog_NegaPojiAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmBOtmzquzlC",
        "outputId": "0a64601a-0b6c-4a29-a3ea-afea94db2551"
      },
      "source": [
        "!pip install mecab-python3\n",
        "# 形態素分析ライブラリーMeCab と 辞書(mecab-ipadic-NEologd)のインストール \n",
        "!apt-get -q -y install sudo file mecab libmecab-dev mecab-ipadic-utf8 git curl python-mecab > /dev/null\n",
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git > /dev/null \n",
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n > /dev/null 2>&1\n",
        "!pip install mecab-python3 > /dev/null\n",
        "# シンボリックリンクによるエラー回避\n",
        "!ln -s /etc/mecabrc /usr/local/etc/mecabrc\n",
        "!pip install neologdn\n",
        "!pip install jaconv\n",
        "\n",
        "import collections\n",
        "from collections import namedtuple\n",
        "import jaconv\n",
        "import MeCab\n",
        "import neologdn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mecab-python3\n",
            "  Downloading mecab_python3-1.0.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (574 kB)\n",
            "\u001b[K     |████████████████████████████████| 574 kB 35.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: mecab-python3\n",
            "Successfully installed mecab-python3-1.0.5\n",
            "Cloning into 'mecab-ipadic-neologd'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 75 (delta 5), reused 54 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (75/75), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting neologdn\n",
            "  Downloading neologdn-0.5.1.tar.gz (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: neologdn\n",
            "  Building wheel for neologdn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neologdn: filename=neologdn-0.5.1-cp37-cp37m-linux_x86_64.whl size=172974 sha256=4b25b6e938e9c8df355f766bb8d7e9fc7617f75225b2eeb21b743f91b5e456c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/15/5c/55b33d02e16129ef81313e4c86e473d6dd1cecf7317a525a9b\n",
            "Successfully built neologdn\n",
            "Installing collected packages: neologdn\n",
            "Successfully installed neologdn-0.5.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jaconv\n",
            "  Downloading jaconv-0.3.tar.gz (15 kB)\n",
            "Building wheels for collected packages: jaconv\n",
            "  Building wheel for jaconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jaconv: filename=jaconv-0.3-py3-none-any.whl size=15564 sha256=d2e2825145fff400c9526367b5070801bbb07f5910b635720b664c0d8baad2c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/4f/c2/a2a3b14d0e94f855f4aa8887bf0267bee9ecfb8e62a9ee2d92\n",
            "Successfully built jaconv\n",
            "Installing collected packages: jaconv\n",
            "Successfully installed jaconv-0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBXQcdLkvRKm",
        "outputId": "159acf5c-b647-45fc-d347-3a992336a441"
      },
      "source": [
        "%cd drive/My Drive"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAM0rlMuvRh7",
        "outputId": "23d9ac06-cd1a-4a22-e797-f1cf37e60109"
      },
      "source": [
        "df = pd.read_csv('./data/review.csv').reset_index()\n",
        "print(df)\n",
        "# dic = pd.read_csv('./dic/dic_shop_in_view03.csv').reset_index()\n",
        "# print(dic)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     index  Unnamed: 0  store_id store_name                 genre  rate  \\\n",
            "0        0           0         1        本湖月  大阪難波駅 322m / 懐石・会席料理  4.57   \n",
            "1        1           1         1        本湖月  大阪難波駅 322m / 懐石・会席料理  4.57   \n",
            "2        2           2         1        本湖月  大阪難波駅 322m / 懐石・会席料理  4.57   \n",
            "3        3           3         1        本湖月  大阪難波駅 322m / 懐石・会席料理  4.57   \n",
            "4        4           4         1        本湖月  大阪難波駅 322m / 懐石・会席料理  4.57   \n",
            "..     ...         ...       ...        ...                   ...   ...   \n",
            "460    460         460         4         米増    福島駅 654m / 懐石・会席料理  4.33   \n",
            "461    461         461         4         米増    福島駅 654m / 懐石・会席料理  4.33   \n",
            "462    462         462         4         米増    福島駅 654m / 懐石・会席料理  4.33   \n",
            "463    463         463         4         米増    福島駅 654m / 懐石・会席料理  4.33   \n",
            "464    464         464         4         米増    福島駅 654m / 懐石・会席料理  4.33   \n",
            "\n",
            "     review_cnt                                             review  \n",
            "0           198  長年の伺いたかった本湖月さんようやく訪問する事が出来ました。大阪のど真ん中、なんばの近く法善...  \n",
            "1           198  Instagram pateknautilus40https://www.instagram...  \n",
            "2           198  背筋が伸びる日本料理のお店です。最も美しい日本料理を高貴なお道具で頂く。季節の移り変わりと季...  \n",
            "3           198  写真NGとの事なので、外観写真のみです！テキストからご想像ください(笑)まずは、じゃばら水。...  \n",
            "4           198  ３月は春らしく雛祭りの節句や貝祭りをイメージにした可憐で華やかなお料理で特にライトアップされ...  \n",
            "..          ...                                                ...  \n",
            "460         105     大阪の人気店。お任せで16,000円のコスパは半端無い。お料理の写真はOKだがアップは禁止。  \n",
            "461         105  旨い以外の単語が見当たらず。良く考え抜かれた品々でそりゃ多数は受け付けられぬハズ。二度と行け...  \n",
            "462         105                         レアな鱧の炭火焼き鮨と鱧の炊き込みご飯が絶品でした。  \n",
            "463         105  胃に優しい、というか、薄味で本当にきれいなお出汁。ブリ大根の美味しいこと。白魚を焼いてご飯と...  \n",
            "464         105  ★ミシュラン★★ゴ・エ・ミヨ・ジャポン★★★日本料理 百名店 2021★★★★食べログ アワ...  \n",
            "\n",
            "[465 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgCR2Yl-vTXD"
      },
      "source": [
        "change_reviews = []\n",
        "for review in df['review']:\n",
        "  review = neologdn.normalize(review)\n",
        "  review = review.replace('@', 'アット')\n",
        "  review = review.replace('＠', 'アット')\n",
        "  review = review.replace('■', '')\n",
        "  review = review.replace('リピ', 'リピート')\n",
        "  review = review.replace('good', '良い')\n",
        "  review = review.replace('コスパ', 'コストパフォーマンス')\n",
        "  review = review.replace('いいです', '良い')\n",
        "  review = review.replace('よかった', '良い')\n",
        "  review = review.replace('します', 'する')\n",
        "  review = review.replace('しません', 'しない')\n",
        "  review = re.split('[。.！!?？!?♪★☆(´･`)*^]', review)\n",
        "  change_reviews.append(' '.join(review))\n",
        "reviews_df = pd.DataFrame(change_reviews, columns=['review'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vzKTamIvVjh"
      },
      "source": [
        "#http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt\n",
        "#上のURL開いてダウンロードする\n",
        "#テキストファイル読み込み\n",
        "\n",
        "with open('./data/japanese.txt', 'r', encoding='utf-8') as f:\n",
        "  stopwords = [w.strip() for w in f]\n",
        "  stopwords = list(stopwords)\n",
        "stopwords.append('*')\n",
        "\n",
        "with open ('./dic/辞書_店_内観0 - 内観.csv', 'r', encoding = 'utf-8') as f:\n",
        "  #単語・読み仮名・品詞・スコアに分割してリストとして格納\n",
        "  negapoji_list = [negapoji_word.split(',') for negapoji_word in  f.readlines()]\n",
        "negapoji_df = pd.DataFrame(negapoji_list)\n",
        "#jaconvを使って読み仮名を全てカタカナに変換\n",
        "# negapoji_df['reading'] = negapoji_df['reading'].apply(lambda x : jaconv.hira2kata(x))\n",
        "#なぜか読みや品詞まで同じなのに、異なるスコアが割り当てられていたものがあったので重複を削除\n",
        "# negapoji_df = negapoji_df[~negapoji_df[['base_form', 'reading', 'pos']].duplicated()]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WILfjKTvYE5"
      },
      "source": [
        "class NegaPojiAnalysis():\n",
        "  def __init__(self, reviews_df, negapoji_list, stopwords):\n",
        "    self.reviews_df = reviews_df\n",
        "    self.negapoji_list = negapoji_list\n",
        "    self.stopwords = stopwords\n",
        "    self.path = \"-Ochasen -d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\"\n",
        "    self.tagger = MeCab.Tagger(self.path)\n",
        "\n",
        "  def tokenize(self):\n",
        "    word_list = []\n",
        "    for i, review in enumerate(self.reviews_df['review']):\n",
        "        node = self.tagger.parseToNode(review)\n",
        "        while node:\n",
        "          surface = node.surface\n",
        "          pos = node.feature.split(\",\")[0]\n",
        "          pos_detail1 = node.feature.split(\",\")[1]\n",
        "          pos_detail2 = node.feature.split(\",\")[2]\n",
        "          pos_detail3 = node.feature.split(\",\")[3]\n",
        "          infl_type = node.feature.split(\",\")[4]  \n",
        "          infl_form = node.feature.split(\",\")[5]\n",
        "          base_form = node.feature.split(\",\")[6]\n",
        "          if len(node.feature.split(\",\")) >= 8:\n",
        "            reading = node.feature.split(\",\")[7]\n",
        "          if pos == '名詞' or pos == '動詞' or pos == '形容詞' or pos == '副詞':\n",
        "            word_list.append([i, surface, pos, pos_detail1, pos_detail2, pos_detail3, infl_type, infl_form, base_form, reading])\n",
        "          node = node.next\n",
        "    word_df = pd.DataFrame(word_list, columns = ['index', 'surface', 'pos', 'pos_detail1', 'pos_detail2', 'pos_detail3', 'infl_type', 'infl_form', 'base_form', 'reading'])\n",
        "    word_df['pos'] = word_df['pos'].apply(lambda negapoji_list : negapoji_list.split(',')[0])\n",
        "    # print(word_df['base_form'])\n",
        "    return word_df\n",
        "\n",
        "  # def generate_negapoji_score(self, word_df, negapoji_df):\n",
        "  #   print('word_df', word_df)\n",
        "  #   print('negapoji_df', negapoji_df)\n",
        "\n",
        "  #   score_result_df = pd.merge(word_df, negapoji_df, on = ['base_form', 'pos', 'reading'], how = 'left')\n",
        "  #   print(score_result_df)\n",
        "  #   return score_result_df\n",
        "\n",
        "  def generate_review_score(self, parse_text_df, negapoji_list):\n",
        "    result = []\n",
        "    resultScore = 0\n",
        "    for i in range(len(parse_text_df)-1):\n",
        "            # テキストをそれぞれ格納する。\n",
        "            text = parse_text_df['base_form'][i] # 任意の単語\n",
        "            if i != 0: # 前単語\n",
        "                textBefore = parse_text_df['base_form'][i-1]\n",
        "            else:\n",
        "                textBefore = ''\n",
        "            if i == len(parse_text_df):\n",
        "              textAfter = ''\n",
        "            else:\n",
        "              textAfter = parse_text_df['base_form'][i+1] # 後単語 or それ以外\n",
        "              \n",
        "            for j in range(len(negapoji_list)-1):\n",
        "                #  print(col[col[1].isin([text]) and col[2].isin([textBefore]) and col[3].isin([textAfter])])\n",
        "                # if negapoji_list[j][1] == text and (negapoji_list[j][2] == textBefore and negapoji_list[j][3] == textAfter):\n",
        "                #   resultScore += negapoji_list[j][4]\n",
        "                # # elif negapoji_list[j][1] == text and (negapoji_list[j][2] == textBefore and negapoji_list[j][3] != textAfter):\n",
        "                # #   resultScore += negapoji_list[j][4]\n",
        "              \n",
        "            # break\n",
        "    print(resultScore) \n",
        "        # temp_df = self.negapoji_list[i]\n",
        "        # text = self.reviews_df['review'][i]\n",
        "        #text = ''.join(list(temp_df['word']))\n",
        "        # score = temp_df['score'].astype(float).sum()\n",
        "        #スコアをスコアが付与されている単語数で割った値を算出\n",
        "        # score_r = score/temp_df['score'].astype(float).count()\n",
        "        # result.append([i, text, score,score_r])\n",
        "    result_df = pd.DataFrame(result, columns = ['index', 'review', '累計スコア', '標準化スコア']).sort_values(by = '標準化スコア', ascending=False).reset_index(drop = True)\n",
        "    return result_df"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmSfKPcrvlTc",
        "outputId": "a56bd2c6-4306-4d71-d98c-2f9ef4f64984"
      },
      "source": [
        "negapoji_analysis = NegaPojiAnalysis(reviews_df, negapoji_list, stopwords)\n",
        "parse_text_df = negapoji_analysis.tokenize()\n",
        "# score_result_df = negapoji_analysis.generate_negapoji_score(parse_text_df, negapoji_df)\n",
        "\n",
        "review_result_df = negapoji_analysis.generate_review_score(parse_text_df, negapoji_list)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUklewg1v8fm"
      },
      "source": [
        "review_result_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjCsaRA9xEQ9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}